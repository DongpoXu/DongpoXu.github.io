<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/xu.jpg"><link rel="icon" type="image/png" sizes="32x32" href="/images/xu.jpg"><link rel="icon" type="image/png" sizes="16x16" href="/images/xu.jpg"><link rel="mask-icon" href="/images/xu.jpg" color="#222"><meta name="baidu-site-verification" content="true"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/lib/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css"><script src="/lib/pace/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"www.xudongpo.cn",root:"/",scheme:"Muse",version:"7.8.0",exturl:!0,sidebar:{position:"right",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!1,style:"mac"},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!0,color:"#222",save:"manual"},fancybox:!0,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!0},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="Python爬虫-爬取京东商品  因为要教实验室的其他“小朋友”，所以自己要在课余时间学下 Python，昨天突发奇想，之前在爬取淘宝的过程中免不了遇到问题，那么在爬取其他网站的时候也会遇到问题。俗话说：问题才是最好的老师。（PS：编的）那么就不墨迹，目标一转，爬一下京东，练练手，本文不对代码做过多讲解，只讲解遇到的问题。 首先查一下京东的 robots 协议？（一直看不太懂，还得好好查，嗯～）"><meta property="og:type" content="article"><meta property="og:title" content="Python爬取京东商品"><meta property="og:url" content="https://www.xudongpo.cn/posts/60ee2c07/index.html"><meta property="og:site_name" content="Xu-Blog"><meta property="og:description" content="Python爬虫-爬取京东商品  因为要教实验室的其他“小朋友”，所以自己要在课余时间学下 Python，昨天突发奇想，之前在爬取淘宝的过程中免不了遇到问题，那么在爬取其他网站的时候也会遇到问题。俗话说：问题才是最好的老师。（PS：编的）那么就不墨迹，目标一转，爬一下京东，练练手，本文不对代码做过多讲解，只讲解遇到的问题。 首先查一下京东的 robots 协议？（一直看不太懂，还得好好查，嗯～）"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.xudongpo.cn/posts/60ee2c07/第一次请求.png"><meta property="og:image" content="https://www.xudongpo.cn/posts/60ee2c07/第二次请求.png"><meta property="article:published_time" content="2019-05-22T08:05:29.000Z"><meta property="article:modified_time" content="2019-05-22T08:05:29.000Z"><meta property="article:author" content="Dongpo Xu"><meta property="article:tag" content="Python"><meta property="article:tag" content="爬虫"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.xudongpo.cn/posts/60ee2c07/第一次请求.png"><link rel="canonical" href="https://www.xudongpo.cn/posts/60ee2c07/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>Python爬取京东商品 | Xu-Blog</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">Xu-Blog</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description"><span id="description">养一猫一狗，猫叫啵啵，狗叫没想好~~</span></p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a></li><li class="menu-item menu-item-sentence"><a href="/sentence/" rel="section"><i class="fa fa-fw fa-heart"></i>句子</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a></li><li class="menu-item menu-item-case"><a href="/case/" rel="section"><i class="fa fa-fw fa-flask"></i>案例</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div><a role="button" class="book-mark-link book-mark-link-fixed"></a> <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL0Rvbmdwb1h1" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="100" height="100" viewBox="0 0 250 250" style="fill:#000;color:#eee8aa;position:absolute;top:0;border:0;left:0;transform:scale(-1,1)" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://www.xudongpo.cn/posts/60ee2c07/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/xu.jpg"><meta itemprop="name" content="Dongpo Xu"><meta itemprop="description" content="许东坡的个人博客，未来的日子一起努力"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Xu-Blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Python爬取京东商品</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-05-22 16:05:29" itemprop="dateCreated datePublished" datetime="2019-05-22T16:05:29+08:00">2019-05-22</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a> </span></span><span id="/posts/60ee2c07/" class="post-meta-item leancloud_visitors" data-flag-title="Python爬取京东商品" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/posts/60ee2c07/#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/posts/60ee2c07/" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>4.5k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p style="font-size:20px;font-weight:800">Python爬虫-爬取京东商品</p><p>因为要教实验室的其他“小朋友”，所以自己要在课余时间学下 Python，昨天突发奇想，之前在爬取淘宝的过程中免不了遇到问题，那么在爬取其他网站的时候也会遇到问题。俗话说：问题才是最好的老师。（PS：编的）那么就不墨迹，目标一转，爬一下京东，练练手，本文不对代码做过多讲解，只讲解遇到的问题。</p><p>首先查一下京东的 robots 协议？（一直看不太懂，还得好好查，嗯～）<a id="more"></a>内容如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Disallow: /?*</span><br><span class="line">Disallow: /pop/*.html</span><br><span class="line">Disallow: /pinpai/*.html?*</span><br><span class="line">User-agent: EtaoSpider</span><br><span class="line">Disallow: /</span><br><span class="line">User-agent: HuihuiSpider</span><br><span class="line">Disallow: /</span><br><span class="line">User-agent: GwdangSpider</span><br><span class="line">Disallow: /</span><br><span class="line">User-agent: WochachaSpider</span><br><span class="line">Disallow: /</span><br></pre></td></tr></table></figure><p>emmmm…我这小程序，嗯没啥影响，爬吧(&gt;^ω^&lt;) 。</p><p>进入<span class="exturl" data-url="aHR0cHM6Ly93d3cuamQuY29tLw==" title="https://www.jd.com/">京东主页<i class="fa fa-external-link"></i></span>，在搜索框中搜索“手机”回车。我们发现链接跳转到了以“<span class="exturl" data-url="aHR0cHM6Ly9zZWFyY2guamQuY29tL+KAnQ==" title="https://search.jd.com/”">https://search.jd.com/”<i class="fa fa-external-link"></i></span>开头的页面。</p><p>默认链接如下：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://search.jd.com/Search?keyword=手机&amp;enc=utf-8&amp;wq=手机&amp;pvid=6e7105bfd9294f7480ce2ab531eae353</span><br></pre></td></tr></table></figure><p>手机是我们搜索的关键词，后面的 id 啥的看不懂，不管，跳转到下一页面。我们取出第二、三页找找规律。</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://search.jd.com/Search?keyword=手机&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=手机&amp;cid2=653&amp;cid3=655&amp;page=3&amp;s=56&amp;click=0</span><br><span class="line">https://search.jd.com/Search?keyword=手机&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=手机&amp;cid2=653&amp;cid3=655&amp;page=5&amp;s=108&amp;click=0</span><br></pre></td></tr></table></figure><p>我们可以发现如下规律：</p><ul><li>前面部分基本一样，之后搜索的 <strong>&amp;keyword</strong> 变化；</li><li><strong>&amp;page</strong> 表示的是页面，规律是 <strong>i*2-1</strong>；</li><li><strong>&amp;s</strong> 没找到规律，不管；</li></ul><p>我们通过这个规律就可以获取到对应的每个 html 页面了。</p><p>获取到 html 页面后，在商品信息中寻找，找到商品价格和名称对应的，是 p-price 和 p-name 为类的两个 div。</p><p>我们通过 BeautifulSoup 获取对应的 dom 元素，提取其中的信息。然后写入，打印即可。</p><p>源码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 京东定向爬取搜索信息</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 获取URL页面</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHTMLText</span>(<span class="params">url, code=<span class="string">&#x27;utf-8&#x27;</span></span>):</span></span><br><span class="line">    head = &#123;</span><br><span class="line">        <span class="string">&#x27;referer&#x27;</span>: <span class="string">&#x27;https://search.jd.com/&#x27;</span>,  <span class="comment"># 每个页面的后半部分数据，是通过下拉然后再次请求，会做来源检查。</span></span><br><span class="line">        <span class="string">&#x27;user-agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Cookie&#x27;</span>: <span class="string">&#x27;dasgfagda&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, timeout=<span class="number">30</span>, headers=head)</span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        r.encoding = code</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;获取URL页面失败&quot;</span></span><br><span class="line"><span class="comment"># 解析html信息</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parsePage</span>(<span class="params">ilt, html</span>):</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        soup = BeautifulSoup(html, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">        nameInfo = soup.find_all(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;p-name&#x27;</span>&#125;)</span><br><span class="line">        priceInfo = soup.find_all(<span class="string">&#x27;div&#x27;</span>, attrs=&#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;p-price&#x27;</span>&#125;)</span><br><span class="line">        <span class="comment"># print(nameInfo)</span></span><br><span class="line">        <span class="comment"># print(priceInfo)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nameInfo)):</span><br><span class="line">            titlelst = nameInfo[i].find(<span class="string">&#x27;em&#x27;</span>).text.split()</span><br><span class="line">            name = <span class="string">&quot;&quot;</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(titlelst)):  <span class="comment"># 此处要注意循环变量不能混淆，与JS不同</span></span><br><span class="line">                <span class="comment"># 注意！！！此处之前是选择了截取长度，但是截取长度导致了后几个页面有些数据丢失，不知道为什么 :TODO</span></span><br><span class="line">                name = name + titlelst[j] + <span class="string">&quot; &quot;</span></span><br><span class="line">            price = priceInfo[i].find(<span class="string">&#x27;strong&#x27;</span>).text</span><br><span class="line">            <span class="keyword">if</span> (price == <span class="string">&#x27;￥&#x27;</span>):  <span class="comment"># 特殊情况，特殊处理</span></span><br><span class="line">                price = <span class="string">&#x27;￥&#x27;</span> + priceInfo[i].find(<span class="string">&#x27;strong&#x27;</span>)[<span class="string">&#x27;data-price&#x27;</span>]</span><br><span class="line">            ilt.append([price, name])</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">&quot;解析HTML内容失败&quot;</span>)</span><br><span class="line"><span class="comment"># 打印商品信息</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printGoodList</span>(<span class="params">ilt</span>):</span></span><br><span class="line">    tplt = <span class="string">&quot;&#123;:4&#125;\t&#123;:8&#125;\t&#123;:16&#125;&quot;</span></span><br><span class="line">    print(tplt.<span class="built_in">format</span>(<span class="string">&quot;序号&quot;</span>, <span class="string">&quot;价格&quot;</span>, <span class="string">&quot;名称&quot;</span>))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> g <span class="keyword">in</span> ilt:</span><br><span class="line">        count = count + <span class="number">1</span></span><br><span class="line">        print(tplt.<span class="built_in">format</span>(count, g[<span class="number">0</span>], g[<span class="number">1</span>]))</span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    pages = <span class="built_in">input</span>(<span class="string">&quot;请输入要爬取的页数 &quot;</span>)</span><br><span class="line">    goods = <span class="string">&#x27;手机&#x27;</span></span><br><span class="line">    depth = <span class="built_in">eval</span>(pages)</span><br><span class="line">    timeID = <span class="string">&#x27;%.5f&#x27;</span> % time.time()  <span class="comment"># 时间戳保留后五位</span></span><br><span class="line">    <span class="comment"># print(timeID)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            print(<span class="string">&quot;以下是第 ------ %d ------ 页数据&quot;</span> % (i + <span class="number">1</span>))</span><br><span class="line">            info_list = []</span><br><span class="line">            url = <span class="string">&#x27;https://search.jd.com/Search?keyword=&#x27;</span> + goods + <span class="string">&#x27;&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=&#x27;</span> + goods + <span class="string">&#x27;&amp;cid2=653&amp;cid3=655&amp;page=&#x27;</span> + <span class="built_in">str</span>(</span><br><span class="line">                (i + <span class="number">1</span>) * <span class="number">2</span> - <span class="number">1</span>) + <span class="string">&#x27;&amp;click=0&#x27;</span>  <span class="comment"># 此处注意 应该给i加1，注意细节</span></span><br><span class="line">            html = getHTMLText(url)</span><br><span class="line">            parsePage(info_list, html)</span><br><span class="line">            url = <span class="string">&#x27;https://search.jd.com/s_new.php?keyword=&#x27;</span> + goods + <span class="string">&#x27;&amp;enc=utf-8&amp;qrst=1&amp;rt=1&amp;stop=1&amp;vt=2&amp;wq=&#x27;</span> + goods + <span class="string">&#x27;&amp;cid2=653&amp;cid3=655&amp;page=&#x27;</span> + <span class="built_in">str</span>(</span><br><span class="line">                (i + <span class="number">1</span>) * <span class="number">2</span>) + <span class="string">&#x27;&amp;scrolling=y&amp;log_id=&#x27;</span> + <span class="built_in">str</span>(timeID) + <span class="string">&#x27;&amp;tpl=3_M&#x27;</span></span><br><span class="line">            html = getHTMLText(url)</span><br><span class="line">            parsePage(info_list, html)</span><br><span class="line">            printGoodList(info_list)</span><br><span class="line">            time.sleep(<span class="number">1</span>)  <span class="comment"># 提升视觉效果</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">main()</span><br></pre></td></tr></table></figure><p style="font-size:20px;font-weight:800">遇到的问题：</p><ul><li><strong>cookie 登录</strong></li></ul><p>在淘宝爬取中已经讲过了，爬取京东需要登录自己的账户，然后将对应的 cookie 信息添加在 headers 里面。<br>详情请见…<a href="../posts/8f666c53/">定向爬取淘宝商品</a></p><ul><li><strong>二次请求</strong></li></ul><p>京东不像淘宝，你进入之后，就给你这一页的所有信息，而是在你下拉的时候，它悄悄地做了第二次请求。对比如下图：</p><p><img src="第一次请求.png" style="width:700px" alt="第一次请求"><br><img src="第二次请求.png" style="width:700px" alt="第二次请求"></p><p>所以我们需要将第二次请求的 url 链接也拿出来做对比，这次多了时间戳。</p><p>需要引入 time 库，生成时间戳加在链接里面既可。</p><ul><li><strong>来源检查</strong></li></ul><p>同样第二次请求做了一次来源检查，需要在 headers 里面加入 referer，机智：=￣ ω ￣=</p><ul><li><strong>没有问题</strong></li></ul><p>for 循环是从 0 开始，请不要大意(PS:丢人的说)</p><ul><li><strong>特殊情况</strong></li></ul><p>有个别数据有特殊情况，获得的 html 并没有 text 数据，而是在元素中自定义属性 data-price，所以，对特殊情况做判断，然后替换数据。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if (price == &#x27;￥&#x27;):  # 特殊情况，特殊处理</span><br><span class="line">  price = <span class="string">&#x27;￥&#x27;</span> + priceInfo[i].find(<span class="string">&#x27;strong&#x27;</span>)[<span class="string">&#x27;data-price&#x27;</span>]</span><br></pre></td></tr></table></figure><ul><li><strong>循环长度</strong></li></ul><p>要注意循环长度不同带来的问题，在打印 name 的部分，我开始时候考虑的是不需要打印那么长的数据，所以对数据做了分割，然后拼接，拼接长度由变量决定，这样可以随时修改，但我固定为显示前三个的时候，在第六、七页之后，打印的数据开始丢失，html 数据没问题。后来经过测验发现，所有的数据并不是长度一致的，这就导致，如果使用了固定长度，会报错，然后 emmm 就 gg 了。</p><p>这些细节也是要注意的，共勉～～</p><p>有问题请在评论区留言，我会及时回复(๑• . •๑)</p></div><div><div style="text-align:center;color:#555;font-size:18px">End~~请支持原创<i class="fa fa-paw"></i>撒花=￣ω￣=花撒</div></div><div class="reward-container"><div>如果您读文章后有收获，可以打赏我喝咖啡哦～</div><button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'>打赏</button><div id="qr" style="display:none"><div style="display:inline-block"><img src="/images/common.png" alt="Dongpo Xu 微信·QQ·支付宝"><p>微信·QQ·支付宝</p></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Python/" rel="tag"><i class="fa fa-tag"></i> Python</a> <a href="/tags/%E7%88%AC%E8%99%AB/" rel="tag"><i class="fa fa-tag"></i> 爬虫</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/b7fbd3ad/" rel="prev" title="JS设计模式-单例模式"><i class="fa fa-chevron-left"></i> JS设计模式-单例模式</a></div><div class="post-nav-item"><a href="/posts/f426f44c/" rel="next" title="生活中的仪式感">生活中的仪式感 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener("tabs:register",()=>{let e=CONFIG.comments["activeClass"];if(CONFIG.comments.storage&&(e=localStorage.getItem("comments_active")||e),e){let t=document.querySelector(`a[href="#comment-${e}"]`);t&&t.click()}}),CONFIG.comments.storage&&window.addEventListener("tabs:click",t=>{t.target.matches(".tabs-comment .tab-content .tab-pane")&&(t=t.target.classList[1],localStorage.setItem("comments_active",t))})</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Dongpo Xu" src="/images/xu.jpg"><p class="site-author-name" itemprop="name">Dongpo Xu</p><div class="site-description" itemprop="description">许东坡的个人博客，未来的日子一起努力</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">99</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">55</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL0Rvbmdwb1h1" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;DongpoXu"><i class="fa fa-fw fa-github"></i>GitHub</span> </span><span class="links-of-author-item"><span class="exturl" data-url="bWFpbHRvOmFlbG91c2RwQDE2My5jb20=" title="E-Mail → mailto:aelousdp@163.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</span> </span><span class="links-of-author-item"><span class="exturl" data-url="aHR0cHM6Ly9sZWV0Y29kZS1jbi5jb20vdS9hZWxvdXNkcC8=" title="LeetCode → https:&#x2F;&#x2F;leetcode-cn.com&#x2F;u&#x2F;aelousdp&#x2F;"><i class="fa fa-fw fa-code"></i>LeetCode</span></span></div><div class="links-of-blogroll motion-element"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><span class="exturl" data-url="aHR0cHM6Ly96cG02ODMueHl6" title="https:&#x2F;&#x2F;zpm683.xyz">午後のお茶で一杯</span></li><li class="links-of-blogroll-item"><span class="exturl" data-url="aHR0cHM6Ly9pdHNjbG91ZHkuZ2l0ZWUuaW8vYmxvZy8=" title="https:&#x2F;&#x2F;itscloudy.gitee.io&#x2F;blog&#x2F;">ItsCloudy</span></li><li class="links-of-blogroll-item"><span class="exturl" data-url="aHR0cHM6Ly9hc2RmdjE5MjkuZ2l0aHViLmlvLw==" title="https:&#x2F;&#x2F;asdfv1929.github.io&#x2F;">1929's Home</span></li></ul></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><div class="gonganBeian"><img src="/images/备案图标.png" style="display:inline-block"><span class="exturl" data-url="aHR0cDovL3d3dy5iZWlhbi5nb3YuY24vcG9ydGFsL3JlZ2lzdGVyU3lzdGVtSW5mbz9yZWNvcmRjb2RlPTIyMDEwNDAyMDAwODM4">吉公网安备 22010402000838号</span></div><div class="icpBeian"><span class="post-meta-divider">|</span><span class="exturl" data-url="aHR0cHM6Ly9iZWlhbi5taWl0Lmdvdi5jbg==">吉ICP备 - 20003200号-1</span></div></div><div class="copyright">&copy; <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="fa fa-spinner"></i> </span><span class="author" itemprop="copyrightHolder">DongpoXu</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="站点总字数">305k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">4:37</span></div><script type="text/javascript" src="/js/src/crash_cheat.js"></script><script type="text/javascript" src="/js/src/typed.js"></script><script>var options={strings:["养一猫一狗，猫叫夜宵，狗叫宵夜","山有扶苏，隰有荷华","不见子都，乃见狂且","你都没坚持，谈什么未来"],typeSpeed:200,loop:!0,loopCount:1/0,backSpeed:200,cursorChar:"^ω^"},typed=new Typed("#description",options)</script></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/fancybox/dist/jquery.min.js"></script><script src="/lib/fancybox/dist/jquery.fancybox.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/local-search.js"></script><script>NexT.utils.loadComments(document.querySelector("#valine-comments"),()=>{NexT.utils.getScript("https://cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js",()=>{var i=["nick","mail","link"],e="nick,mail,link".split(",").filter(e=>i.includes(e));new Valine({el:"#valine-comments",verify:!0,notify:!0,appId:"IgXUs8o4trUx8BIt56GW7Ac4-gzGzoHsz",appKey:"5EN3Kw3h7ER24APkfyxQKkdp",placeholder:"欢迎～说点什么吧～",avatar:"mm",meta:e,pageSize:"10",visitor:!0,lang:"zh-cn",path:location.pathname,recordIP:!1,serverURLs:""})},window.Valine)})</script></body></html>